{"pageProps":{"postData":{"id":"post1","lang":"en","title":"Kafka Producer Stability Check: Ensuring Message Safety in Apache Kafka","section":"tech","date":"2025-05-04","tags":"Kafka, Producer, Reliability, Apache Kafka","thumbnail":"https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ojt2w7s7rr9kws35r2yg.png","description":"Learn how to build fault-tolerant Kafka producers that survive rolling patches and broker failures","searchKeywords":"Kafka, producer, reliability, message safety, rolling patch, broker failure","preview":"\nDuring a recent incident, our team observed message loss from a Kafka producer during an Amazon MSK rolling patch. What began as a routine "},"detail":"\nDuring a recent incident, our team observed message loss from a Kafka producer during an Amazon MSK rolling patch. What began as a routine upgrade quickly uncovered hidden weaknesses in our producer's configuration.\n\nAs we dug into the issue, I developed a clearer picture of how Kafka producers interact with broker leaders and what it truly takes to build a production-grade, fault-tolerant producer pipeline. This post captures those insights—covering critical configuration options that influence message delivery reliability and mechanisms behind them.\n\nLet's begin by examining how message loss can occur during a rolling patch—and then broaden our lens to explore other scenarios where Kafka messages might be at risk.\n\n## A Successful Scenario: How Rolling Patches Should Work\n\nAmazon MSK performs \"rolling patches\" to apply updates while minimizing disruption by restarting brokers one at a time.\n\nIn a well-configured environment, the patching process follows a series of fault-tolerant steps that ensure message delivery remains uninterrupted:\n\n**1. Initial State**:\n\n   * All brokers (1, 2, and 3) are operational.\n   * Partition 1 has its leader on Broker 1, and its ISR (In-Sync Replicas) includes {Broker 1, 2, 3}.\n   * The producer is configured for high resilience, using settings such as a high `retries` count, `acks=all`, and `enable.idempotence=true`.\n\n![kafka cluster setting](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/8gb5ff7le7bqsma2ufk7.png)\n\n**2. Patch Initiation (Target: Broker 1)**:\n\n   * MSK initiates a controlled shutdown of Broker 1.\n   * The Kafka controller detects the shutdown and reassigns leadership of Partition 1 to another ISR member, such as Broker 2.\n   * This metadata change is propagated throughout the cluster.\n\n![kafka cluster](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/634g8uf9aklhre2o55lq.png)\n\n**3. Producer's Initial Reaction**:\n\n   * The producer may still believe Broker 1 is the leader.\n   * Send attempts to Broker 1 fail, triggering connection errors or `NotLeaderOrFollowerException`.\n\n**4. Metadata Refresh and Retry Logic**:\n\n   * The producer, equipped with a high retry count, continues retrying.\n   * These failures trigger a metadata refresh (either reactively or via `metadata.max.age.ms`).\n   * The producer receives updated metadata indicating Broker 2 as the new leader and updates its internal routing.\n\n![metadata](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ckjr45rpuli7cf5lb2k8.png)\n\n**5. Successful Message Delivery**:\n\n   * The message is retried and sent to Broker 2.\n   * Broker 2 persists the message locally and replicates it to Broker 3 (Broker 1 is offline).\n   * With acknowledgments from all in-sync replicas (2 and 3), and `min.insync.replicas=2` satisfied, Broker 2 responds with a final ACK.\n\n![ISR](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/vx16uutcmelb9dcm1lny.png)\n\nAs a result, the message is successfully delivered, even though the original leader was taken offline. Kafka's failover mechanism, combined with a resilient producer configuration, ensures no data is lost.\n\n---\n\nHowever, in our case, the `retries` setting was limited to 5 (Kafka versions before 2.1 defaulted to 0), and `retry.backoff.ms` was set to its default value of 100ms. This left less than a second of total retry time.\n\nLeader re-election and metadata propagation didn't complete within that narrow window. As a result, the producer exhausted all retry attempts before it became aware of the new leader.\n\nEventually, the producer gave up. If the application doesn't explicitly handle this failure—such as routing to a Dead Letter Queue—the message is lost.\n\nDespite the presence of other brokers, the producer failed to reach the correct leader within its constrained retry window, resulting in irreversible message loss.\n\n---\n\n## Why Leader Re-Election Isn't Instant\n\nWhen a partition leader becomes unavailable—such as during a rolling patch—Kafka initiates a leader re-election process to maintain availability and consistency. This process is coordinated by a special broker known as the **Controller**.\n\nTo understand this process, it's important to first review the roles brokers play in replication. Kafka topics are divided into partitions, and each partition is replicated across multiple brokers. Among these, one broker is elected as the **Leader**, responsible for all read and write operations for that partition. All producers and consumers interact solely with the leader. The other brokers serve as **Followers**, replicating data from the leader to remain synchronized.\n\n### The Role of Controller Broker\n\nThe Controller Broker functions as the cluster's brain. It monitors broker health (via ZooKeeper or KRaft), detects failures, and orchestrates the leader re-election process. Importantly, the controller itself is designed to be highly available.\n\nHere's how the re-election process typically unfolds:\n\n1. **Failure Detection**: The controller notices the leader is unresponsive, usually via missed heartbeats or expired sessions.\n\n2. **Partition Identification**: It identifies all partitions for which the failed broker was the leader.\n\n3. **ISR Consultation**: For each affected partition, it consults the ISR (In-Sync Replica) list to determine which followers are fully up to date.\n\n4. **Safe Leader Assignment**: A new leader is selected from the ISR (assuming `unclean.leader.election.enable=false`), ensuring no data loss.\n\n5. **Metadata Update**: The controller records the leadership change in the cluster's metadata (ZooKeeper or KRaft).\n\n6. **Cluster-Wide Propagation**: The new metadata is broadcast to all brokers.\n\n7. **Client Refresh**: Kafka clients (like producers) either detect errors like `NotLeaderOrFollowerException` or refresh metadata after the `metadata.max.age.ms` interval. This enables them to learn the identity of the new leader and resume operations.\n\n### The Timing Challenge\n\nEach step introduces some delay. In practice, the full process—from detecting failure to clients updating their metadata—can take several seconds to tens of seconds, depending on cluster size, network conditions, and whether you're running ZooKeeper or KRaft.\n\nThis delay is precisely the danger window: if the producer exhausts its retries before learning about the new leader, the message will be lost.\n\nUnderstanding this timing is critical to configuring your producer appropriately—and is exactly what our team learned the hard way.\n\n---\n\n## Building a Resilient Kafka Producer: Key Configurations\n\nA resilient Kafka producer doesn't happen by accident—it's the result of carefully chosen configuration settings that account for real-world failure scenarios like broker downtime and leader re-elections.\n\nBelow are the key settings that significantly improve the producer's reliability:\n\n### `acks=all`\n\nThis setting ensures that the leader broker waits for acknowledgment from all in-sync replicas (ISRs) before responding to the producer. It offers the highest level of durability.\n\n* **Benefit**: Protects against data loss if the leader fails after writing but before replication.\n* **Risk without it**: With `acks=1`, the leader acknowledges after writing locally. If it fails before replication, the message is lost.\n\n### `retries=Integer.MAX_VALUE`\n\nAllows the producer to retry failed sends indefinitely (bounded by `delivery.timeout.ms`). Starting with Kafka 2.1, this is the **default** value.\n\n* **Benefit**: Handles transient failures like leader unavailability or network hiccups.\n\n* **Risk without it**: Limited retries can exhaust before leader re-election or metadata refresh completes. (bounded by `delivery.timeout.ms`).\n\n### `enable.idempotence=true`\n\nPrevents duplicate message delivery when retries occur, while also preserving message order within a single partition.\n\n* **How it works**: When idempotence is enabled, each Kafka producer is assigned a unique **Producer ID (PID)**. For every partition the producer writes to, it attaches a **monotonically increasing sequence number** to each message. Brokers track the last successfully written sequence number for each PID/partition pair.\n\n  If the broker receives a message with a sequence number it has already seen—or one that is out of order—it treats it as a duplicate and silently discards it.\n\n* **Guaranteeing Order**: Idempotent producers also preserve message ordering per partition. This is especially critical during retries. To safely maintain this ordering, Kafka enforces that `max.in.flight.requests.per.connection` must be set to **5 or fewer**. Higher values may cause out-of-order retries, which Kafka cannot deduplicate reliably.\n\n* **Requirements**:\n\n  * `acks=all` must be enabled to ensure replication safety.\n  * `retries` must be greater than 0 to allow resending.\n  * `max.in.flight.requests.per.connection` must be ≤ 5 to keep idempotence active.\n\nBy meeting these conditions, Kafka ensures **exactly-once semantics per partition** within a single producer session—without sacrificing performance or message integrity.\n\nThis mechanism is crucial for mission-critical systems, where even a single duplicate or out-of-order event could lead to inconsistent downstream state.\n\n* **How it works**: Assigns sequence numbers to messages and uses producer IDs to detect and discard duplicates.\n* **Requirement**: Must be used with `acks=all` and `retries>0`.\n\n### Additional Settings to Consider\n\n* `max.in.flight.requests.per.connection<=5`: Controls how many messages can be sent to a broker without receiving acknowledgments.\n\n  When `enable.idempotence=true`, Kafka requires this value to be **≤ 5** to ensure safe deduplication. If it's higher, Kafka disables idempotence to avoid state management complexity.\n\n* `request.timeout.ms`: Time the producer waits for a response from the broker. Should generally be less than or equal to `delivery.timeout.ms`.\n\nBy tuning these configurations appropriately, your producer becomes resilient to transient errors, rolling patches, and even brief leader outages—dramatically reducing the risk of message loss.\n\n## When Retries Aren't Enough: Why You Still Need a DLQ\n\nEven with idempotence enabled and retries set to the maximum, Kafka producers can still encounter unrecoverable failures. Scenarios like extended broker outages, prolonged network partitions, message serialization errors, or misconfigurations (e.g., messages exceeding size limits) can cause final send failures.\n\nThat's where a **Dead Letter Queue (DLQ)** comes in.\n\n### What Is a DLQ?\n\nA Dead Letter Queue is a secondary Kafka topic or external system where messages are routed after repeated delivery attempts have failed.\n\n### Why You Still Need a DLQ\n\n* **Transient vs. Terminal Failures**: Kafka's retry mechanisms handle transient failures. DLQs catch terminal ones.\n* **Delivery Timeout**: Even with `retries=Integer.MAX_VALUE`, Kafka producers ultimately give up if `delivery.timeout.ms` is exceeded.\n* **Non-Retriable Errors**: Errors like schema validation failure, record size violations, or authentication issues won't be fixed by retrying.\n* **Observability**: DLQs give teams visibility into failed messages for postmortem analysis or manual replay.\n\n### DLQ Design Best Practices\n\n1. **Use a Separate Kafka Topic**: Isolate failed messages in a clearly named topic (e.g., `my-topic.DLQ`).\n2. **Include Contextual Metadata**: Such as error reason, original topic and partition, timestamp, and message key.\n3. **Avoid Blocking Main Flow**: Ensure DLQ writes are async or decoupled so they don't slow down the main processing path.\n4. **Secure and Monitor**: Apply appropriate ACLs and set up alerting/monitoring on DLQ volume.\n\nImplementing a DLQ is a pragmatic and necessary layer of protection. It ensures that when all else fails, your data doesn't disappear silently—and your team has the tooling needed to recover from unexpected edge cases.\n\n---\n\n## Testing Your Configuration: Simulating Failure Scenarios\n\nReading documentation and tuning configurations is only part of the equation—validating your Kafka producer setup through failure simulations is essential to ensure true resilience.\n\nHere's a step-by-step guide to stress-testing your producer under real-world conditions:\n\n### 1. **Spin Up a Test Cluster**\n\nSet up a local Kafka cluster with at least three brokers using Docker Compose or test infrastructure.\n\n* Ensure replication factor = 3 and `min.insync.replicas = 2` for target topics.\n\n### 2. **Configure Your Producer**\n\nPrepare two configurations:\n\n* **Baseline**: Low retries, no idempotence (e.g., `retries=3`, `acks=1`).\n* **Resilient**: Recommended settings (`acks=all`, `retries=Integer.MAX_VALUE`, `enable.idempotence=true`, appropriate backoff and timeouts).\n\n### 3. **Simulate Rolling Broker Restart**\n\nWhile actively producing messages:\n\n* Restart one broker at a time to mimic a rolling patch.\n* Introduce controlled shutdown and observe producer logs.\n\n### 4. **Observe and Compare**\n\n* Do messages get lost or duplicated?\n* Do retries behave as expected?\n* Are DLQ fallbacks triggered for unrecoverable failures?\n\nBy rigorously testing your Kafka setup under adverse conditions, you can verify that your configuration not only looks good on paper—but actually holds up under stress. This ensures peace of mind in production environments where message loss is not an option.\n\n---\n\n## Conclusion: Owning Message Reliability End-to-End\n\nKafka's durability guarantees are strong, but not infallible. Without a properly configured producer, even a routine rolling patch can lead to silent message loss—something no team wants to discover after the fact.\n\nThrough this real-world failure and recovery, we learned that ensuring message safety is a shared responsibility between Kafka and the application. It requires more than just enabling replication—it demands careful attention to producer configuration, retry behavior, idempotence, DLQ design, and validation through controlled failure testing.\n\nBy:\n\n* Setting `acks=all`\n* Enabling idempotence\n* Maximizing retries with meaningful backoff\n* Using DLQs for unrecoverable cases\n\n—you can confidently build systems that survive the unexpected.\n\nMessage safety isn't a default. It's a design choice. And with the right choices, Kafka becomes not just fast and scalable, but truly reliable.\n","lang":"en","allPostsInOtherLang":[{"id":"post10","lang":"ko","title":"10억 달러짜리 실수 해결하기: JSpecify와 NullAway를 사용한 최신 Java Null 안전성","date":"2025-09-24","section":"tech","tags":"Java, JSpecify, Null 안전성, NullPointerException, 정적 분석","thumbnail":"https://media2.dev.to/dynamic/image/width=1000,height=420,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Ftotx4mdagz9nsegld5mr.png","description":"JSpecify 어노테이션과 NullAway 정적 분석을 사용하여 현대 Java 애플리케이션에서 NullPointerException을 제거하는 방법 학습","searchKeywords":"JSpecify, NullAway, Java null 안전성, NullPointerException 방지, 정적 분석","translationSlug":"post9","preview":"\n자바 프로그래밍을 처음 시작한 개발자부터 20년 경력의 시니어 개발자까지, 경력을 불문하고 개발자들이 가장 자주 마주치는 에러는 **NullPointerException**일 것입니다.\n\n![Top Crash Reasons](https://dev-t"},{"id":"post22","lang":"ko","title":"Anthropic 엔지니어들의 프롬프트 엔지니어링 팁","date":"2025-06-24","section":"tech","tags":"AI","thumbnail":"https://media2.dev.to/dynamic/image/width=1000,height=420,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fdzzrfth8zqdnrhbj9538.png","description":"Anthropic 엔지니어들이 공유한 가치 있는 프롬프트 엔지니어링 팁과 통찰","searchKeywords":"프롬프트 엔지니어링, AI 팁, Anthropic, LLM 베스트 프랙티스","translationSlug":"post7","preview":"\n[youtube (AI prompt engineering: A deep dive)](https://www.youtube.com/watch?v=T9aRN5JkmL8&t=2463s)에서 Anthropic 엔지니어들이 그들의 프롬프트 작성 팁과 경험을 공"},{"id":"post23","lang":"ko","title":"조인 테이블이 왜 생기지? @JoinColumn으로 해결하는 연관관계 매핑의 비밀","section":"tech","thumbnail":"https://velog.velcdn.com/images/wooyong99/post/6fdebd14-5fe8-4959-b085-74edb6bc4d46/image.png","tags":"JPA","date":"2024-10-10 10:00","searchKeywords":"jpa, JoinColumn, 외래 키, 외래 키 제약 조건","description":"JoinColumn","preview":"\n`@JoinColumn`은 외래키를 매핑할 때 사용한다. 즉, 한 엔티티에서 다른 엔티티를 참조(조인)하는데 사용되는 필드를 지정하는 역할을 한다.\n\n```java\n@Entity  \n@Table(name = \"orders\")  \n@Getter\n@No"},{"id":"post29","lang":"ko","title":"내부 메서드 호출시 트랜잭션이 적용되지 않는 이슈","section":"tech","thumbnail":"https://velog.velcdn.com/images/uiurihappy/post/0c13062e-e5cb-45f0-9727-a9ef018b1ffc/image.png","tags":"transactional","date":"2024-10-01 10:00","searchKeywords":"transactional, spring, aop","description":"Transactional 내부 메서드 호출시 트랜잭션이 적용되지 않는 이슈","preview":"\n# @Transactional 동작 원리\n\n## AOP와 프록시 패턴을 통한 트랜잭션 관리\n\nAOP는 엔터프라이즈 애플리케이션 개발에서 객체지향 프로그래밍(OOP)의 한계를 보완해주는 보조적인 프로그래밍 기법이다. 이를 통해 트랜잭션, 캐싱, 로깅 "},{"id":"post30","lang":"ko","title":"Gson 라이브러리 InaccessibleObjectException","thumbnail":"https://media.techmaster.vn/api/static/bq0a8rs51co78aldi4p0/lsRpW5hr","section":"tech","tags":"gson, Java","date":"2024-07-02 10:00","searchKeywords":"gson, java","description":"gson","preview":"\nSpring Boot 2.5.x 버전에서 3.2.x 버전으로 마이그레이션 하는 과정에서 InaccessibleObjectException이 발생하였다. Gson 라이브러리를 사용하는 쪽에서 발생한 문제였는데, 이에 대한 트러블 슈팅 과정을 정리해 보"},{"id":"post20","lang":"ko","title":"Fixture Monkey With Kotlin","section":"tech","thumbnail":"https://i.imgur.com/J5SIYtU.png","tags":"test","date":"2024-03-03 10:00","searchKeywords":"fixture monkey, test, fixture","description":"fixtureMonkey","preview":"\n테스트를 작성하다보면 프로덕션 코드를 작성하는 시간보다 테스트를 위한 픽스처를 만드는데 더 많은 시간이 소요될 때가 있다.\n\n테스트를 작성하는데 시간이 많이 들고 번거로울 수록 테스트 코드를 생략하게 되고 결국 결함에 취약한 시스템을 구현할 위험이 "},{"id":"post19","lang":"ko","title":"객체지향과 탈 국지화","section":"tech","thumbnail":"https://i.imgur.com/e584gko.png","tags":"객체지향","date":"2024-02-04 10:00","searchKeywords":"OOP","description":"객체지향과 탈 국지화","preview":"\n최근 두 권의 책을 병행해서 읽는 중인데 서로 조금 상반되는 내용을 읽게 되어 내 생각을 정리해 보는 시간을 가져보았다.\n\n한 권은 펠리너 헤르만스가 쓴 '[프로그래머의 뇌](https://m.yes24.com/Goods/Detail/10591101"},{"id":"post18","lang":"ko","title":"JPA 트랜잭션과 영속성 컨텍스트","section":"tech","thumbnail":"https://images.velog.io/images/dnjscksdn98/post/14072bd8-850b-4d2b-8476-cb5385bbcd36/jpa.png","tags":"JPA","date":"2024-01-07 10:00","searchKeywords":"jpa, entitymanager, 영속성 컨텍스트, 트랜잭션","description":"JPA 트랜잭션과 영속성 컨텍스트","preview":"\n최근 구현한 테스트 코드에서 `@Transactional` 여부에 따라 테스트 결과가 달라지는 문제를 만나게 되었다.\n\n타 서비스로부터 송장 접수 결과에 대한 카프카 메세지를 소비한 다음, 송장 접수에 실패했다면 택배 등록 여부를 실패로 변경하는 로"},{"id":"post17","lang":"ko","title":"GitHub Actions를 통해 CI/CD 구축하기 (feat. Docker, Jib)","thumbnail":"https://miro.medium.com/max/1400/1*DmFbJvnRIiQIyi5xBuIXlQ.png","section":"tech","tags":"tech, 프로젝트, CI/CD, Docker","date":"2022-12-06 10:00","preview":"\n저희 `Text Me` 서비스의 베타 버전이 배포되고 난 뒤에, 사용자들로 부터 수많은 피드백을 받을 수 있었습니다. \n사용자 피드백을 빠르게 반영하다 보니 프로젝트의 빌드 및 배포 주기가 짧아졌고 이러한 과정이 서서히 번거롭게 느껴지기 시작했습니다"},{"id":"post16","lang":"ko","title":"ubuntu 18.04에 Docker 설치하기","section":"tech","thumbnail":"https://www.docker.com/wp-content/uploads/2021/09/Docker-build.png","tags":"infra","date":"2022-12-03 10:00","preview":"\n프로젝트를 진행하면서 도커 허브에 올라가있는 이미지를 가져와서 배포 환경에서 실행해야 하는 요구사항이 발생하였습니다. \n\n이를 위해서 ubuntu환경에 docker를 설치했던 과정을 공유해보겠습니다.\n\n## Docker가 지원하는 OS\n\n다음은 do"},{"id":"post15","lang":"ko","title":"[오브젝트] 13장 - 서브클래싱과 서브타이핑","section":"tech","thumbnail":"https://wikibook.co.kr/images/cover/m/9791158391409.png","tags":"객체지향","date":"2022-11-29 10:00","preview":"\n상속이 사용되는 두 가지 용도\n\n- 타입 계층을 구현하는 것\n    - 부모 클래스\n        - 일반적인 개념을 구현\n        - 부모 클래스는 자식 클래스의 일반화\n    - 자식 클래스\n        - 특수한 개념을 구현\n      "},{"id":"post14","lang":"ko","title":"[오브젝트] 9장 - 유연한 설계","section":"tech","thumbnail":"https://wikibook.co.kr/images/cover/m/9791158391409.png","tags":"객체지향","date":"2022-11-02 10:00","preview":"\n## 1. 개방-폐쇄 원칙 (Open-Closed Principle)\n\n- 개체는 확장에 대해 열려있어야 하고, 수정에 대해서는 닫혀 있어야한다.\n    - 확장에 열려있다.\n        - 새로운 동작을 추가해서 어플리케이션의 기능을 확장할 수 "},{"id":"post13","lang":"ko","title":"어노테이션 기반 MVC로 리팩터링하기 - MVC 2편","thumbnail":"https://i.imgur.com/b9vvtK7.png","section":"tech","tags":"Spring, MVC","date":"2022-10-17 10:00","preview":"\n이번 포스트에서는 [이전 포스트](https://headf1rst.github.io/TIL/mvc1)에서 구현한 MVC 프레임워크를 \n어노테이션 기반의 MVC로 점진적으로 리팩토링해 나가는 과정에 대해서 다뤄보도록 하겠다.\n\n## 1. 불편함을 감지"},{"id":"post12","lang":"ko","title":"MVC 프레임워크 만들기 - MVC 1편","thumbnail":"https://i.imgur.com/b9vvtK7.png","section":"tech","tags":"Spring, MVC","date":"2022-10-08 10:00","preview":"\n7월에 [넥스트 스텝](https://edu.nextstep.camp/)에서 진행하는 [만들면서 배우는 스프링 3기](https://edu.nextstep.camp/s/I7LCaCf3)에 참여하였습니다.\n\n이 포스트는 해당 과정에서 스스로 고민하며 "},{"id":"post11","lang":"ko","title":"[오브젝트] 7장 - 객체 분해","section":"tech","thumbnail":"https://wikibook.co.kr/images/cover/m/9791158391409.png","tags":"객체지향","date":"2022-10-02 10:00","preview":"\n모든 프로그래밍 패러다임은 추상화와 분해의 관점에서 설명 가능\n\n## 추상화 메커니즘\n시스템을 분해하는 방법을 프로시저와 데이터 추상화중 하나를 중심으로 하여 결정해야한다.\n\n- 1. 프로시저 추상화\n    - 소프트웨어가 무엇을 **해야**하는지 "},{"id":"post9","lang":"ko","title":"다중 요청 처리를 위한 ThreadPool 적용하기","thumbnail":"https://i.imgur.com/mHibXLP.jpg","section":"tech","tags":"Spring, ThreadPool","date":"2022-09-20 10:00","preview":"\n프레임워크는 개발자가 쉽고 편하게 개발을 할 수 있도록 많은 기술을 추상화해서 제공한다.\n\n스프링 또한 많은 부분이 추상화 되었으며 개발자 스스로가 의문을 갖지 않는다면, 모른채 넘어갈 기술들이 여럿 존재한다.\n\n오늘은 그러한 기술들 중, 개발자들을"},{"id":"post8","lang":"ko","title":"[오브젝트] 5장 - 책임 할당하기","section":"tech","thumbnail":"https://wikibook.co.kr/images/cover/m/9791158391409.png","tags":"객체지향","date":"2022-09-19 10:00","preview":"\n## 책임 중심 설계\n\n- 어떤 객체에게 어던 책임을 할당할지 결정해야한다\n- 문제 해결을 위한 다양한 책임 할당 방법이 존재하며 일종의 트레이드오프 활동이다.\n- 상황과 문맥에 따라 최적의 책임 할당 방법을 선택해야한다.\n\n- 책임 중심 설계를 위"},{"id":"post7","lang":"ko","title":"[오브젝트] 4장 - 설계 품질과 트레이드오프","thumbnail":"https://wikibook.co.kr/images/cover/m/9791158391409.png","section":"tech","tags":"객체지향","date":"2022-09-12 10:00","preview":"\n좋은 객체지향 설계란 올바른 객체에게 올바른 책임을 할당하면서 캡슐화를 통해 낮은 결합도와 높은 응집도를 가진 구조를 창조하는 것\n\n- 구현\n    - 변경될 가능성이 높은 부분\n- 인터페이스\n    - 상대적으로 안정적인 부분\n\n- 변경의 정도에 "},{"id":"post6","lang":"ko","title":"[오브젝트] 3장 - 역할, 책임, 협력","section":"tech","thumbnail":"https://wikibook.co.kr/images/cover/m/9791158391409.png","tags":"객체지향","date":"2022-09-05 10:00","preview":"\n- 객체지향의 본질 : 협력하는 객체들의 공동체를 창조하는 것\n    - 기능 구현을 위해 어떤 협력이 필요하고 협력을 위해 어떤 역할, 책임이 필요한지 파악\n\n- 객체들은 메시지를 주고 받으며 협력한다\n\n- `협력`\n    - 어플리케이션 기능 구"},{"id":"post5","lang":"ko","title":"[오브젝트] 2장 - 객체지향 프로그래밍","section":"tech","thumbnail":"https://wikibook.co.kr/images/cover/m/9791158391409.png","tags":"객체지향","date":"2022-08-29 10:00","preview":"\n클래스를 먼저 결정하고, 어떤 `속성`과 `메서드`가 필요한지 고민하는것리 아니라 `객체`에 초점을 맞춰야한다\n\n1. 어떤 클래스가 필요한지 이전에 어떤 객체가 필요한지 고민하라\n   클래스는 공통적인 상태, 행동을 공유하는 객체를 추상화한것\n\n2."},{"id":"post4","lang":"ko","title":"[오브젝트] 1장 - 객체, 설계","section":"tech","thumbnail":"https://wikibook.co.kr/images/cover/m/9791158391409.png","tags":"객체지향","date":"2022-08-22 10:00","preview":"\n`패러다임` - 한 시대의 사회 전체가 공유하는 이론 혹은 방법.\n절차형 → 객체지향으로 패러다임 전환을 맞았다.\n\n프로그래밍 패러다임은 과거의 패러다임을 폐기시키는 혁명적 패러다임이 아니라 과거의 패러다임을 개선하는 `발전적 패러다임`이다.\n\n객체"},{"id":"post3","lang":"ko","title":"내가 블로그를 새로 시작하는 이유","thumbnail":"https://i.imgur.com/HbkinoQ.jpg","section":"tech","tags":"회고","date":"2022-08-02 10:00","preview":"\n## 앵무새식 블로그 글\n\n처음 블로그를 시작하는 경우에 `TIL (Today I Learned)` 을 목적으로 하루에 하나의 포스팅을 하는 경우를 주위에서 많이 봤고 나 또한 그랬다.\n\n그 당시에는 하나의 포스팅을 마치고 나면 마치 해당 주제에 대"},{"id":"post2","lang":"ko","title":"Static 변수 저장위치와 JVM 구조의 변화","section":"tech","thumbnail":"https://i.imgur.com/5AJJwhh.png","tags":"Java, JVM","date":"2022-07-11 10:00","searchKeywords":"자바, jvm, 정적 변수","description":"Static 변수 저장위치와 JVM 구조의 변화","preview":"\nStatic 키워드를 사용하여 정적 변수와 정적 메서드를 만들수 있는데, 이들을 정적 멤버 (혹은 클래스 멤버) 라고 합니다.\n\n```java\nclass Lesson {\n\t\tstatic int score = 0;\n\t\tstatic String grad"},{"id":"post1","lang":"ko","title":"CORS, 알고보니 우리편?","section":"tech","thumbnail":"https://user-images.githubusercontent.com/85024598/236966566-6127653c-7540-485e-859f-01240e7e7154.png","tags":"프로젝트","date":"2022-05-26 10:00","preview":"\nServer Side Template 방식이 아닌 프론트와 백으로 나눠서 API 통신을 하는\n프로젝트의 경우, 열에 아홉은 만나게 되는게 바로 `CORS` 입니다.\n\n아니나 다를까 현재 진행중인 프로젝트에서도 CORS 관련 이슈가 올라왔습니다.\n\n!"}]},"__N_SSG":true}